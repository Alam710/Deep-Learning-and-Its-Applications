{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alam710/Deep-Learning-and-Its-Applications/blob/main/word_embedding_fastText_dan_layer_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlhBc9B2E2lc",
        "outputId": "d534cb1b-4239-46bc-fb37-90b3be9e5c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nft6Wo4oIAAU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "from tqdm import tqdm\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "import os, re, csv, math, codecs\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tensorflow as tf\n",
        "\n",
        "torch.manual_seed(2301978431);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3gWKbe7LDEv"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/gdrive/MyDrive/fastt/IMDB Dataset.csv'\n",
        "w2v_path = '/content/gdrive/MyDrive/fastt/wiki-news-300d-1M.vec'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hV4WO2o6E2lp"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gruRIPElJkBT"
      },
      "outputs": [],
      "source": [
        "df.sentiment = df.sentiment.apply(lambda x: 1 if x=='positive' else 0)\n",
        "\n",
        "df['kfold'] = -1\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "y = df.sentiment.values\n",
        "kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "\n",
        "for fold, (train_, valid_) in enumerate(kf.split(X=df, y=y)):\n",
        "    df.loc[valid_, 'kfold'] = fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Ji5zjvqhLWjX",
        "outputId": "f8fb2ffd-cc24-4397-8333-953a8ee2be13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review  sentiment  kfold\n",
              "0      I found out about this film because Jewish Ben...          0      0\n",
              "1      I saw this at my in-laws' house one night when...          0      0\n",
              "2      The idea of making a miniseries about the Berl...          0      0\n",
              "3      This movie was recommended to me so we went to...          0      0\n",
              "4      A 1957 Roger Corman non epic in which a sundry...          0      0\n",
              "...                                                  ...        ...    ...\n",
              "49995  Though predictable and contrived, not a bad mo...          0      4\n",
              "49996  First off, this is the worst movie I've ever s...          0      4\n",
              "49997  Definitely the worst movie I have ever seen......          0      4\n",
              "49998  A bit quirky and bordering bad taste; but inte...          1      4\n",
              "49999  This movie has great style, fantastic visuals ...          1      4\n",
              "\n",
              "[50000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4d02adf-8371-49ab-939d-1b0b0c489675\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>kfold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I found out about this film because Jewish Ben...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I saw this at my in-laws' house one night when...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The idea of making a miniseries about the Berl...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This movie was recommended to me so we went to...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A 1957 Roger Corman non epic in which a sundry...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>Though predictable and contrived, not a bad mo...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>First off, this is the worst movie I've ever s...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>Definitely the worst movie I have ever seen......</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>A bit quirky and bordering bad taste; but inte...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>This movie has great style, fantastic visuals ...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4d02adf-8371-49ab-939d-1b0b0c489675')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4d02adf-8371-49ab-939d-1b0b0c489675 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4d02adf-8371-49ab-939d-1b0b0c489675');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnNQXtR9J1X_",
        "outputId": "65cee35a-4937-4fb8-e268-e5fc5508a063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "999995it [01:09, 14368.30it/s]\n"
          ]
        }
      ],
      "source": [
        "fasttext_embedding = {}\n",
        "f = codecs.open(w2v_path, encoding='utf-8')\n",
        "for line in tqdm(f):\n",
        "  values = line.rstrip().rsplit(' ')\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  fasttext_embedding[word] = coefs\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKW6hn_LJ5zl"
      },
      "outputs": [],
      "source": [
        "class IMDBDataset:\n",
        "  def __init__(self, reviews, targets):\n",
        "    self.reviews = reviews\n",
        "    self.target = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    review = torch.tensor(self.reviews[index,:], dtype = torch.long)\n",
        "    target = torch.tensor(self.target[index], dtype = torch.float)\n",
        "    \n",
        "    return {'review': review, 'target': target}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFuxpPesKKbK"
      },
      "outputs": [],
      "source": [
        "def create_embedding_matrix(word_index, embedding_dict=None, d_model=100):\n",
        "  embedding_matrix = np.zeros((len(word_index) + 1, d_model))\n",
        "  for word, index in word_index.items():\n",
        "    if word in embedding_dict:\n",
        "      embedding_matrix[index] = embedding_dict[word]\n",
        "  return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKoTvacoJ8ty"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, embedding_matrix):\n",
        "    super(LSTM, self).__init__()\n",
        "    num_words = embedding_matrix.shape[0]\n",
        "    embedding_dim = embedding_matrix.shape[1]\n",
        "    self.embedding = nn.Embedding(num_embeddings=num_words, embedding_dim=embedding_dim)\n",
        "    self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype = torch.float32))\n",
        "    self.embedding.weight.requires_grad = False\n",
        "    self.lstm = nn.LSTM(embedding_dim, 128, bidirectional=True, batch_first=True)\n",
        "    self.out = nn.Linear(512, 1)\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    hidden, _ = self.lstm(x)\n",
        "    avg_pool= torch.mean(hidden, 1)\n",
        "    max_pool, index_max_pool = torch.max(hidden, 1)\n",
        "    out = torch.cat((avg_pool, max_pool), 1)\n",
        "    out = self.out(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff1U-LYFJ-0n"
      },
      "outputs": [],
      "source": [
        "def train(data_loader, model, optimizer, device):\n",
        "  model.train()\n",
        "  for data in data_loader:\n",
        "    reviews = data['review']\n",
        "    targets = data['target']\n",
        "    reviews = reviews.to(device, dtype = torch.long)\n",
        "    targets = targets.to(device, dtype = torch.float)\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(reviews)\n",
        "    loss = nn.BCEWithLogitsLoss()(predictions, targets.view(-1,1))\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke-KFRu2KCh6"
      },
      "outputs": [],
      "source": [
        "def evaluate(data_loader, model, device):\n",
        "  final_predictions = []\n",
        "  final_targets = []\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for data in data_loader:\n",
        "      reviews = data['review']\n",
        "      targets = data['target']\n",
        "      reviews = reviews.to(device, dtype = torch.long)\n",
        "      targets = targets.to(device, dtype=torch.float)\n",
        "      predictions = model(reviews)\n",
        "      predictions = predictions.cpu().numpy().tolist()\n",
        "      targets = data['target'].cpu().numpy().tolist()\n",
        "      final_predictions.extend(predictions)\n",
        "      final_targets.extend(targets)\n",
        "  return final_predictions, final_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fETLfYr4KEB4"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 8\n",
        "EPOCHS = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VanR6i-HKN5M"
      },
      "outputs": [],
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(df.review.values.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hfGdm5UKQgw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a3b2859-80f0-484e-f063-000c9550fa94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training model\n",
            "FOLD:0, epoch: 0, accuracy_score: 0.8667\n",
            "FOLD:0, epoch: 1, accuracy_score: 0.8818\n",
            "FOLD:0, epoch: 2, accuracy_score: 0.8875\n",
            "FOLD:0, epoch: 3, accuracy_score: 0.8923\n",
            "FOLD:0, epoch: 4, accuracy_score: 0.8967\n",
            "training model\n",
            "FOLD:1, epoch: 0, accuracy_score: 0.8596\n",
            "FOLD:1, epoch: 1, accuracy_score: 0.8847\n",
            "FOLD:1, epoch: 2, accuracy_score: 0.892\n",
            "FOLD:1, epoch: 3, accuracy_score: 0.897\n",
            "FOLD:1, epoch: 4, accuracy_score: 0.8928\n",
            "training model\n",
            "FOLD:2, epoch: 0, accuracy_score: 0.874\n",
            "FOLD:2, epoch: 1, accuracy_score: 0.8924\n",
            "FOLD:2, epoch: 2, accuracy_score: 0.8994\n",
            "FOLD:2, epoch: 3, accuracy_score: 0.8998\n",
            "FOLD:2, epoch: 4, accuracy_score: 0.8971\n",
            "training model\n",
            "FOLD:3, epoch: 0, accuracy_score: 0.862\n",
            "FOLD:3, epoch: 1, accuracy_score: 0.886\n",
            "FOLD:3, epoch: 2, accuracy_score: 0.8909\n",
            "FOLD:3, epoch: 3, accuracy_score: 0.8963\n",
            "FOLD:3, epoch: 4, accuracy_score: 0.8946\n",
            "training model\n",
            "FOLD:4, epoch: 0, accuracy_score: 0.8676\n",
            "FOLD:4, epoch: 1, accuracy_score: 0.8836\n",
            "FOLD:4, epoch: 2, accuracy_score: 0.8871\n",
            "FOLD:4, epoch: 3, accuracy_score: 0.8932\n",
            "FOLD:4, epoch: 4, accuracy_score: 0.8894\n"
          ]
        }
      ],
      "source": [
        "embedding_matrix = create_embedding_matrix(tokenizer.word_index, embedding_dict=fasttext_embedding, d_model=300)\n",
        "\n",
        "for fold in range(5):\n",
        "    train_df = df[df.kfold != fold].reset_index(drop=True)\n",
        "    valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
        "    \n",
        "    xtrain = tokenizer.texts_to_sequences(train_df.review.values)\n",
        "    xtest = tokenizer.texts_to_sequences(valid_df.review.values)\n",
        "    \n",
        "    xtrain = tf.keras.preprocessing.sequence.pad_sequences(xtrain, maxlen=MAX_LEN)\n",
        "    xtest = tf.keras.preprocessing.sequence.pad_sequences(xtest, maxlen=MAX_LEN)\n",
        "    \n",
        "    train_dataset = IMDBDataset(reviews=xtrain, targets=train_df.sentiment.values)\n",
        "    \n",
        "    train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size = TRAIN_BATCH_SIZE, num_workers=2)\n",
        "    valid_dataset = IMDBDataset(reviews=xtest, targets=valid_df.sentiment.values)\n",
        "    valid_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = VALID_BATCH_SIZE, num_workers=1)\n",
        "    \n",
        "    device = torch.device('cuda')\n",
        "    model_fasttext = LSTM(embedding_matrix)\n",
        "    model_fasttext.to(device)\n",
        "    optimizer = torch.optim.Adam(model_fasttext.parameters(), lr=1e-3)\n",
        "    \n",
        "    print('training model')\n",
        "   \n",
        "    for epoch in range(EPOCHS):\n",
        "        train(train_data_loader, model_fasttext, optimizer, device)\n",
        "        outputs, targets = evaluate(valid_data_loader, model_fasttext, device)\n",
        "        outputs = np.array(outputs) >= 0.5\n",
        "        accuracy = metrics.accuracy_score(targets, outputs)\n",
        "        print(f'FOLD:{fold}, epoch: {epoch}, accuracy_score: {accuracy}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": " word embedding fastText dan layer LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}