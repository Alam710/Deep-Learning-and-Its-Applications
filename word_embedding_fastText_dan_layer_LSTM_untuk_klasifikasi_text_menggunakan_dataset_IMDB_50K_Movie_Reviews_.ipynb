{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " word embedding fastText dan layer LSTM untuk klasifikasi text menggunakan dataset IMDB 50K Movie Reviews..ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMqoHxbu0WiMYCYuivO4585",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alam710/Deep-Learning-and-Its-Applications/blob/main/word_embedding_fastText_dan_layer_LSTM_untuk_klasifikasi_text_menggunakan_dataset_IMDB_50K_Movie_Reviews_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q4jTSDtffjI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d8b9176-61ca-4ab7-c8dd-de16831e1997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "from tqdm import tqdm\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "import os, re, csv, math, codecs\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tensorflow as tf\n",
        "\n",
        "torch.manual_seed(2301978431);"
      ],
      "metadata": {
        "id": "MWdR0NSpJ40O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/gdrive/MyDrive/Deep Learning Lecture/IMDB Dataset.csv'\n",
        "w2v_path = '/content/gdrive/MyDrive/Deep Learning Lecture/wiki-news-300d-1M.vec'"
      ],
      "metadata": {
        "id": "INdPe_UXJ42z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(dataset_path)"
      ],
      "metadata": {
        "id": "JPMsgMRgJ45V"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sentiment = df.sentiment.apply(lambda x: 1 if x=='positive' else 0)\n",
        "\n",
        "df['kfold'] = -1\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "y = df.sentiment.values\n",
        "kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "\n",
        "for fold, (train_, valid_) in enumerate(kf.split(X=df, y=y)):\n",
        "    df.loc[valid_, 'kfold'] = fold"
      ],
      "metadata": {
        "id": "dexxsRsWJ470"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ehr7tJSzJ4-j",
        "outputId": "9dcadbcd-331d-4198-f2e1-eda4e4c80b3d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review  sentiment  kfold\n",
              "0      It takes an eternity for this typically over-s...          0      0\n",
              "1      First saw this half a lifetime ago on a black-...          1      0\n",
              "2      Let me preface this by going on record, I am a...          0      0\n",
              "3      I won't waste a whole lot of time of this one ...          0      0\n",
              "4      Here is an innovative television drama; which ...          1      0\n",
              "...                                                  ...        ...    ...\n",
              "49995  This whimsical film had the misfortune of bein...          1      4\n",
              "49996  After reading the book, which had a lot of mea...          0      4\n",
              "49997  A whole bunch of teenagers gather around to di...          0      4\n",
              "49998  Yes, you guessed it. Another movie where ident...          0      4\n",
              "49999  The plot has something about white hunters cap...          0      4\n",
              "\n",
              "[50000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d511d5e1-c5f5-489d-8e1a-0712b7d157ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>kfold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It takes an eternity for this typically over-s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>First saw this half a lifetime ago on a black-...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Let me preface this by going on record, I am a...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I won't waste a whole lot of time of this one ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Here is an innovative television drama; which ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>This whimsical film had the misfortune of bein...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>After reading the book, which had a lot of mea...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>A whole bunch of teenagers gather around to di...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>Yes, you guessed it. Another movie where ident...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>The plot has something about white hunters cap...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d511d5e1-c5f5-489d-8e1a-0712b7d157ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d511d5e1-c5f5-489d-8e1a-0712b7d157ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d511d5e1-c5f5-489d-8e1a-0712b7d157ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_embedding = {}\n",
        "f = codecs.open(w2v_path, encoding='utf-8')\n",
        "for line in tqdm(f):\n",
        "  values = line.rstrip().rsplit(' ')\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  fasttext_embedding[word] = coefs\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsODoN7VJ5B7",
        "outputId": "9fe5e0a6-58bf-4505-aac6-f54fd4843c09"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "999995it [01:19, 12646.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class IMDBDataset:\n",
        "  def __init__(self, reviews, targets):\n",
        "    self.reviews = reviews\n",
        "    self.target = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    review = torch.tensor(self.reviews[index,:], dtype = torch.long)\n",
        "    target = torch.tensor(self.target[index], dtype = torch.float)\n",
        "    \n",
        "    return {'review': review, 'target': target}"
      ],
      "metadata": {
        "id": "fBohWfwpJ5Eo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding_matrix(word_index, embedding_dict=None, d_model=100):\n",
        "  embedding_matrix = np.zeros((len(word_index) + 1, d_model))\n",
        "  for word, index in word_index.items():\n",
        "    if word in embedding_dict:\n",
        "      embedding_matrix[index] = embedding_dict[word]\n",
        "  return embedding_matrix"
      ],
      "metadata": {
        "id": "TtjGbAA3J5Gd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, embedding_matrix):\n",
        "    super(LSTM, self).__init__()\n",
        "    num_words = embedding_matrix.shape[0]\n",
        "    embedding_dim = embedding_matrix.shape[1]\n",
        "    self.embedding = nn.Embedding(num_embeddings=num_words, embedding_dim=embedding_dim)\n",
        "    self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype = torch.float32))\n",
        "    self.embedding.weight.requires_grad = False\n",
        "    self.lstm = nn.LSTM(embedding_dim, 128, bidirectional=True, batch_first=True)\n",
        "    self.out = nn.Linear(512, 1)\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    hidden, _ = self.lstm(x)\n",
        "    avg_pool= torch.mean(hidden, 1)\n",
        "    max_pool, index_max_pool = torch.max(hidden, 1)\n",
        "    out = torch.cat((avg_pool, max_pool), 1)\n",
        "    out = self.out(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "b1e1dDLzJ5H7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_loader, model, optimizer, device):\n",
        "  model.train()\n",
        "  for data in data_loader:\n",
        "    reviews = data['review']\n",
        "    targets = data['target']\n",
        "    reviews = reviews.to(device, dtype = torch.long)\n",
        "    targets = targets.to(device, dtype = torch.float)\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(reviews)\n",
        "    loss = nn.BCEWithLogitsLoss()(predictions, targets.view(-1,1))\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "XOLyrU3MJ5Ks"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(data_loader, model, device):\n",
        "  final_predictions = []\n",
        "  final_targets = []\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for data in data_loader:\n",
        "      reviews = data['review']\n",
        "      targets = data['target']\n",
        "      reviews = reviews.to(device, dtype = torch.long)\n",
        "      targets = targets.to(device, dtype=torch.float)\n",
        "      predictions = model(reviews)\n",
        "      predictions = predictions.cpu().numpy().tolist()\n",
        "      targets = data['target'].cpu().numpy().tolist()\n",
        "      final_predictions.extend(predictions)\n",
        "      final_targets.extend(targets)\n",
        "  return final_predictions, final_targets"
      ],
      "metadata": {
        "id": "57pG0CuxJ5M5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 8\n",
        "EPOCHS = 5"
      ],
      "metadata": {
        "id": "2BLbn1C5J5PF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(df.review.values.tolist())"
      ],
      "metadata": {
        "id": "NpU4R5nQKP0P"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = create_embedding_matrix(tokenizer.word_index, embedding_dict=fasttext_embedding, d_model=300)\n",
        "\n",
        "for fold in range(5):\n",
        "    train_df = df[df.kfold != fold].reset_index(drop=True)\n",
        "    valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
        "    \n",
        "    xtrain = tokenizer.texts_to_sequences(train_df.review.values)\n",
        "    xtest = tokenizer.texts_to_sequences(valid_df.review.values)\n",
        "    \n",
        "    xtrain = tf.keras.preprocessing.sequence.pad_sequences(xtrain, maxlen=MAX_LEN)\n",
        "    xtest = tf.keras.preprocessing.sequence.pad_sequences(xtest, maxlen=MAX_LEN)\n",
        "    \n",
        "    train_dataset = IMDBDataset(reviews=xtrain, targets=train_df.sentiment.values)\n",
        "    \n",
        "    train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size = TRAIN_BATCH_SIZE, num_workers=2)\n",
        "    valid_dataset = IMDBDataset(reviews=xtest, targets=valid_df.sentiment.values)\n",
        "    valid_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = VALID_BATCH_SIZE, num_workers=1)\n",
        "    \n",
        "    device = torch.device('cuda')\n",
        "    model_fasttext = LSTM(embedding_matrix)\n",
        "    model_fasttext.to(device)\n",
        "    optimizer = torch.optim.Adam(model_fasttext.parameters(), lr=1e-3)\n",
        "    \n",
        "    print('training model')\n",
        "   \n",
        "    for epoch in range(EPOCHS):\n",
        "        train(train_data_loader, model_fasttext, optimizer, device)\n",
        "        outputs, targets = evaluate(valid_data_loader, model_fasttext, device)\n",
        "        outputs = np.array(outputs) >= 0.5\n",
        "        accuracy = metrics.accuracy_score(targets, outputs)\n",
        "        print(f'FOLD:{fold}, epoch: {epoch}, accuracy_score: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAVAYEHnKP2k",
        "outputId": "f42d8cee-2d99-4c7e-8bd7-6f03dd354b11"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training model\n",
            "FOLD:0, epoch: 0, accuracy_score: 0.803\n",
            "FOLD:0, epoch: 1, accuracy_score: 0.8636\n",
            "FOLD:0, epoch: 2, accuracy_score: 0.8781\n",
            "FOLD:0, epoch: 3, accuracy_score: 0.8864\n",
            "FOLD:0, epoch: 4, accuracy_score: 0.8919\n",
            "training model\n",
            "FOLD:1, epoch: 0, accuracy_score: 0.8021\n",
            "FOLD:1, epoch: 1, accuracy_score: 0.8607\n",
            "FOLD:1, epoch: 2, accuracy_score: 0.8813\n",
            "FOLD:1, epoch: 3, accuracy_score: 0.8869\n",
            "FOLD:1, epoch: 4, accuracy_score: 0.8853\n",
            "training model\n",
            "FOLD:2, epoch: 0, accuracy_score: 0.8193\n",
            "FOLD:2, epoch: 1, accuracy_score: 0.8609\n",
            "FOLD:2, epoch: 2, accuracy_score: 0.8783\n",
            "FOLD:2, epoch: 3, accuracy_score: 0.891\n",
            "FOLD:2, epoch: 4, accuracy_score: 0.8935\n",
            "training model\n",
            "FOLD:3, epoch: 0, accuracy_score: 0.8039\n",
            "FOLD:3, epoch: 1, accuracy_score: 0.8572\n",
            "FOLD:3, epoch: 2, accuracy_score: 0.8796\n",
            "FOLD:3, epoch: 3, accuracy_score: 0.8842\n",
            "FOLD:3, epoch: 4, accuracy_score: 0.8913\n",
            "training model\n",
            "FOLD:4, epoch: 0, accuracy_score: 0.8506\n",
            "FOLD:4, epoch: 1, accuracy_score: 0.8754\n",
            "FOLD:4, epoch: 2, accuracy_score: 0.8896\n",
            "FOLD:4, epoch: 3, accuracy_score: 0.8972\n",
            "FOLD:4, epoch: 4, accuracy_score: 0.8992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wsWgnAELKP5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Od-i69_9KP7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Y8cuxmV3KP-n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}